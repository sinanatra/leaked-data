{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giacomonanni/Documents/Development/leaked-data/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"YOUR_API_KEY\"  \n",
    "BASE_URL = \"https://search.libraryofleaks.org/api/2\"\n",
    "HEADERS = {\"Authorization\": f\"ApiKey {API_KEY}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_collections():\n",
    "    \"\"\"Fetch all available collections.\"\"\"\n",
    "    url = f\"{BASE_URL}/collections\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"results\"]\n",
    "\n",
    "def fetch_schemas(collection_id):\n",
    "    \"\"\"Fetch schemas available in a specific collection.\"\"\"\n",
    "    url = f\"{BASE_URL}/collections/{collection_id}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "    collection_data = response.json()\n",
    "    schema_values = collection_data.get(\"statistics\", {}).get(\"schema\", {}).get(\"values\", {})\n",
    "    print(\"Available schemas in collection:\")\n",
    "    for schema, count in schema_values.items():\n",
    "        print(f\"- {schema} ({count} occurrences)\")\n",
    "    return [{\"key\": schema, \"count\": count} for schema, count in schema_values.items()]\n",
    "\n",
    "def fetch_entities(collection_id, schema, limit=100, offset=0):\n",
    "    \"\"\"Fetch entities from a specific collection and schema.\"\"\"\n",
    "    url = f\"{BASE_URL}/entities\"\n",
    "    params = {\n",
    "        \"collection_id\": collection_id,\n",
    "        \"schema\": schema,\n",
    "        \"filter:schemata\": schema,\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset\n",
    "    }\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"results\"], response.json().get(\"next\")\n",
    "\n",
    "def fetch_entities(collection_id, schema, limit=100, offset=0, additional_filters=None):\n",
    "    \"\"\"Fetch entities from a specific collection with optional filters.\"\"\"\n",
    "    url = f\"{BASE_URL}/entities\"\n",
    "    params = {\n",
    "        \"collection_id\": collection_id,\n",
    "        \"schema\": schema,\n",
    "        \"filter:schemata\": schema,\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset\n",
    "    }\n",
    "    if additional_filters:\n",
    "        params.update(additional_filters)\n",
    "\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"results\"], response.json().get(\"next\")\n",
    "\n",
    "\n",
    "def save_entities_to_csv(entities, filename):\n",
    "    \"\"\"Save entities to a CSV file.\"\"\"\n",
    "    rows = []\n",
    "    for entity in entities:\n",
    "        row = {\n",
    "            \"id\": entity.get(\"id\"),\n",
    "            \"schema\": entity.get(\"schema\"),\n",
    "            \"bodyText\": entity[\"properties\"].get(\"bodyText\", [\"\"])[0],  # First text block\n",
    "            \"fileName\": entity[\"properties\"].get(\"fileName\", [\"\"])[0],  # First filename\n",
    "            \"mimeType\": entity[\"properties\"].get(\"mimeType\", [\"\"])[0],  # First MIME type\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {len(rows)} entities to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections:\n",
      "- 13: Afghanistan Papiere\n",
      "- 18: Airman Teixeira Leaks\n",
      "- 35: Bahamas Registry\n",
      "- 1: BlueLeaks\n",
      "- 29: Chinga La Migra\n",
      "- 14: Constellis\n",
      "- 25: Cryptome Archive (2024)\n",
      "- 15: Documents from US Espionage Den\n",
      "- 19: FBIâ€™s Secret Rules\n",
      "- 21: Fraternal Order of Police\n",
      "- 31: Fuck FBI Friday\n",
      "- 9: Hillary Clinton emails\n",
      "- 6: Hunter Biden emails\n",
      "- 3: Israel Defense Forces (Anonymous For Justice)\n",
      "- 33: Israel Ministry of Justice\n",
      "- 4: Jones Day\n",
      "- 34: Kazakhstan Ministry of Energy\n",
      "- 11: Metropolitan Police Department D.C.\n",
      "- 16: MilicoLeaks\n",
      "- 10: Paramilitary Election Interference\n"
     ]
    }
   ],
   "source": [
    "collections = fetch_collections()\n",
    "print(\"Available collections:\")\n",
    "for col in collections:\n",
    "    print(f\"- {col['id']}: {col['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected:  18\n"
     ]
    }
   ],
   "source": [
    "collection_id = input(\"Enter the ID of the collection you want to explore: \")\n",
    "print(\"Selected: \", collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available schemas in collection:\n",
      "- Image (64 occurrences)\n",
      "- {'key': 'Image', 'count': 64}\n",
      "Selected:  Image\n"
     ]
    }
   ],
   "source": [
    "schemas = fetch_schemas(collection_id)\n",
    "for schema in schemas:\n",
    "    print(f\"- {schema}\")\n",
    "\n",
    "schema = input(\"Enter the schema to use (or press Enter to skip): \")\n",
    "print(\"Selected: \", schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities, next_url = fetch_entities(collection_id, schema, limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 entities to entities_page.csv\n"
     ]
    }
   ],
   "source": [
    "save_entities_to_csv(entities, \"entities_page.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations(entities):\n",
    "    \"\"\"Extract relationships from entities for network visualization.\"\"\"\n",
    "    relations = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        source = entity.get(\"id\")  \n",
    "\n",
    "        for person in entity[\"properties\"].get(\"peopleMentioned\", []):\n",
    "            relations.append({\"source\": source, \"target\": person, \"relationship\": \"mentioned\"})\n",
    "\n",
    "        for company in entity[\"properties\"].get(\"companiesMentioned\", []):\n",
    "            relations.append({\"source\": source, \"target\": company, \"relationship\": \"mentions company\"})\n",
    "\n",
    "        for email in entity[\"properties\"].get(\"emailMentioned\", []):\n",
    "            relations.append({\"source\": source, \"target\": email, \"relationship\": \"mentions email\"})\n",
    "\n",
    "        parents = entity[\"properties\"].get(\"parent\", [])\n",
    "        if isinstance(parents, list):\n",
    "            for parent in parents:\n",
    "                if isinstance(parent, dict):\n",
    "                    target_id = parent.get(\"id\")\n",
    "                    target_schema = parent.get(\"schema\", \"Unknown\")\n",
    "                    if target_id:\n",
    "                        relations.append({\n",
    "                            \"source\": source,\n",
    "                            \"target\": target_id,\n",
    "                            \"relationship\": f\"is child of\"\n",
    "                        })\n",
    "\n",
    "        ancestors = entity[\"properties\"].get(\"ancestors\", [])\n",
    "        if isinstance(ancestors, list):\n",
    "            for ancestor in ancestors:\n",
    "                if isinstance(ancestor, dict):\n",
    "                    target_id = ancestor.get(\"id\")\n",
    "                    target_schema = ancestor.get(\"schema\", \"Unknown\")\n",
    "                    if target_id:\n",
    "                        relations.append({\n",
    "                            \"source\": source,\n",
    "                            \"target\": target_id,\n",
    "                            \"relationship\": f\"has ancestor\"\n",
    "                        })\n",
    "\n",
    "        nested_target = entity.get(\"target\")\n",
    "        if nested_target:\n",
    "            target_id = nested_target.get(\"id\")\n",
    "            target_schema = nested_target.get(\"schema\")\n",
    "            if target_id and target_schema:\n",
    "                relations.append({\n",
    "                    \"source\": source,\n",
    "                    \"target\": target_id,\n",
    "                    \"relationship\": f\"linked to {target_schema}\"\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(relations)\n",
    "\n",
    "\n",
    "def save_relations_to_csv(relations, filename=\"relations.csv\"):\n",
    "    \"\"\"Save extracted relationships to a CSV file.\"\"\"\n",
    "    relations.to_csv(filename, index=False)\n",
    "    print(f\"Saved {len(relations)} relations to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = extract_relations(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 203 relations to relations.csv\n"
     ]
    }
   ],
   "source": [
    "save_relations_to_csv(relations, \"relations.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
